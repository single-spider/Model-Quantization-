# -*- coding: utf-8 -*-
"""Lab_11.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1VuA8mVM5a1ajfXfw7JpatujrP8W8_tVY

##CS 203 : Sentiment Analysis with MLP and Model Optimization Techniques

## 1. Setup and Imports
"""

!pip install prettytable -q

import pandas as pd
import torch
from torch.utils.data import TensorDataset, DataLoader, SubsetRandomSampler
from sklearn.feature_extraction.text import TfidfVectorizer
import torch.nn as nn
import torch.optim as optim
import matplotlib.pyplot as plt
import torch.quantization as quant
import time
import os
from sklearn.model_selection import train_test_split
from prettytable import PrettyTable

"""## 2. Data Loading"""

# URLs for the datasets
train_url = "https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/train.tsv"
test_url = "https://raw.githubusercontent.com/clairett/pytorch-sentiment-classification/master/data/SST2/test.tsv"

# Load DataFrames without header and rename columns
train_df = pd.read_csv(train_url, delimiter='\t', header=None)
train_df.columns = ['sentence', 'label']
test_df = pd.read_csv(test_url, delimiter='\t', header=None)
test_df.columns = ['sentence', 'label']
# Display the first few rows of the training data
print("Training Data Head:")
print(train_df.head())

# Display the first few rows of the test data
print("\nTest Data Head:")
print(test_df.head())

"""## 3. Data Preprocessing (TF-IDF Vectorization)"""

# Initialize TF-IDF Vectorizer
vectorizer = TfidfVectorizer(max_features=10000)  # Limit to 10000 features

# Fit the vectorizer on the training data and transform it
print("Fitting TF-IDF on training data and transforming...")
train_features = vectorizer.fit_transform(train_df['sentence']).toarray()

# Transform the test data using the fitted vectorizer
print("Transforming test data...")
test_features = vectorizer.transform(test_df['sentence']).toarray()

# Get labels as NumPy arrays
train_labels = train_df['label'].values
test_labels = test_df['label'].values

print(f"\nShape of training features: {train_features.shape}")
print(f"Shape of test features: {test_features.shape}")
print(f"Shape of training labels: {train_labels.shape}")
print(f"Shape of test labels: {test_labels.shape}")

"""## 4. PyTorch Data Preparation

"""

# Create TensorDatasets
train_dataset = TensorDataset(torch.tensor(train_features, dtype=torch.float32),
                              torch.tensor(train_labels, dtype=torch.long))
test_dataset = TensorDataset(torch.tensor(test_features, dtype=torch.float32),
                             torch.tensor(test_labels, dtype=torch.long))

# Create initial DataLoaders (train_loader will be redefined after split)
train_loader_full = DataLoader(train_dataset, batch_size=32, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=32)

print(f"Number of training samples: {len(train_dataset)}")
print(f"Number of test samples: {len(test_dataset)}")

"""## 5. Model Definition (MLP)

We define a Multi-Layer Perceptron (MLP) model using PyTorch's `nn.Module`.

*   **Architecture**: The MLP consists of several fully connected (`nn.Linear`) layers with ReLU activation functions (`nn.ReLU`) and Dropout (`nn.Dropout`) for regularization.
    *   Input layer: Takes the TF-IDF feature dimension (10000) as input.
    *   Hidden layers: Reduce dimensionality progressively (512 -> 256 -> 128 -> 64).
    *   Output layer: Produces 2 outputs, corresponding to the scores for the two sentiment classes (negative, positive).
*   **Dropout**: Applied after each ReLU activation in the hidden layers to prevent overfitting by randomly setting a fraction (`dropout_prob=0.3`) of neuron activations to zero during training.
*   **`__init__`**: Initializes the layers sequence.
*   **`forward`**: Defines the forward pass of data through the layers.
"""

class MLP(nn.Module):
    def __init__(self, input_dim=10000, hidden_sizes=[512, 256, 128, 64], output_dim=2, dropout_prob=0.3):
        super(MLP, self).__init__()
        # Define the sequence of layers
        self.layers = nn.Sequential(
            # Layer 1
            nn.Linear(input_dim, hidden_sizes[0]),
            nn.ReLU(),
            nn.Dropout(dropout_prob),

            # Layer 2
            nn.Linear(hidden_sizes[0], hidden_sizes[1]),
            nn.ReLU(),
            nn.Dropout(dropout_prob),

            # Layer 3
            nn.Linear(hidden_sizes[1], hidden_sizes[2]),
            nn.ReLU(),
            nn.Dropout(dropout_prob),

            # Layer 4
            nn.Linear(hidden_sizes[2], hidden_sizes[3]),
            nn.ReLU(),
            nn.Dropout(dropout_prob),

            # Output Layer
            nn.Linear(hidden_sizes[3], output_dim)
        )

    def forward(self, x):
        # Pass input through the sequential layers
        return self.layers(x)

"""## 6. Model Instantiation and Setup


"""

# Instantiate the model
mlp = MLP()

# Helper function to count trainable parameters
def count_parameters(model):
    return sum(p.numel() for p in model.parameters() if p.requires_grad)

print(f"Total trainable parameters: {count_parameters(mlp):,}")

# Define device to use (GPU if available, otherwise CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Move the model to the selected device
mlp = mlp.to(device)

"""## 7. Training Setup

We set up the components needed for the training loop:

*   **Loss Function**: `nn.CrossEntropyLoss` is suitable for classification tasks. It combines `LogSoftmax` and `NLLLoss` in one class and expects raw scores (logits) from the model and class indices as targets.
*   **Optimizer**: `optim.Adam` is an adaptive learning rate optimization algorithm that's widely used and generally performs well.
*   **Epochs**: `num_epochs = 10` defines how many times we iterate over the entire training dataset.
*   **Tracking**: We initialize variables to track the best validation accuracy (`best_val_acc`) for checkpointing and lists to store training loss, validation loss, and validation accuracy for plotting.
*   **Train/Validation Split**: We split the original *training dataset* into a new training set (80%) and a validation set (20%) using `train_test_split` on the indices. This validation set is crucial for monitoring model performance on unseen data during training and preventing overfitting.
*   **Samplers**: `SubsetRandomSampler` is used to create DataLoaders that only sample from the specified training or validation indices.
*   **New DataLoaders**: We create new `train_loader` and `val_loader` using the original `train_dataset` but with the respective samplers to ensure they draw data only from the correct split.
"""

# Loss function
criterion = nn.CrossEntropyLoss()

# Optimizer
optimizer = optim.Adam(mlp.parameters(), lr=1e-3)

# Number of training epochs
num_epochs = 10

# Variables for tracking best model and metrics
best_val_acc = 0.0
train_losses = []
val_losses = []
val_accuracies = []

# Split the training data indices into training and validation sets (80% train, 20% val)
train_indices, val_indices = train_test_split(
    range(len(train_dataset)), test_size=0.2, random_state=42 # Use a fixed random state for reproducibility
)

# Create samplers for training and validation sets
train_sampler = SubsetRandomSampler(train_indices)
val_sampler = SubsetRandomSampler(val_indices)

# Create DataLoaders for training and validation using the samplers
train_loader = DataLoader(train_dataset, batch_size=32, sampler=train_sampler)
val_loader = DataLoader(train_dataset, batch_size=32, sampler=val_sampler)

print(f"Size of new training set: {len(train_indices)}")
print(f"Size of validation set: {len(val_indices)}")

"""## 8. Training Loop

"""

print("Starting Training...")
start_train_time = time.time()

for epoch in range(num_epochs):
    # --- Training Phase ---
    mlp.train()  # Set model to training mode
    running_train_loss = 0.0

    for data, target in train_loader:
        # Move data and target tensors to the configured device
        data, target = data.to(device), target.to(device)

        # Zero the parameter gradients
        optimizer.zero_grad()

        # Forward pass: compute predicted outputs by passing inputs to the model
        outputs = mlp(data)

        # Calculate the batch loss
        loss = criterion(outputs, target)

        # Backward pass: compute gradient of the loss with respect to model parameters
        loss.backward()

        # Perform a single optimization step (parameter update)
        optimizer.step()

        # Update running training loss
        running_train_loss += loss.item() * data.size(0)

    # Calculate average training loss for the epoch
    epoch_train_loss = running_train_loss / len(train_indices)
    train_losses.append(epoch_train_loss)

    # --- Validation Phase ---
    mlp.eval()  # Set model to evaluation mode
    running_val_loss = 0.0
    correct_val = 0
    total_val = 0

    with torch.no_grad():  # Disable gradient calculations
        for data, target in val_loader:
            data, target = data.to(device), target.to(device)
            outputs = mlp(data)
            loss = criterion(outputs, target)
            running_val_loss += loss.item() * data.size(0)
            _, predicted = torch.max(outputs, 1)
            total_val += target.size(0)
            correct_val += (predicted == target).sum().item()

    # Calculate average validation loss and accuracy for the epoch
    epoch_val_loss = running_val_loss / len(val_indices)
    epoch_val_acc = 100.0 * correct_val / total_val
    val_losses.append(epoch_val_loss)
    val_accuracies.append(epoch_val_acc)

    print(f"Epoch {epoch+1}/{num_epochs} - "
          f"Train Loss: {epoch_train_loss:.4f}, "
          f"Val Loss: {epoch_val_loss:.4f}, "
          f"Val Accuracy: {epoch_val_acc:.2f}%" ) # Removed incorrect variable reference

    # Save checkpoint if validation accuracy improves
    if epoch_val_acc > best_val_acc:
        print(f"Validation accuracy improved ({best_val_acc:.2f}% --> {epoch_val_acc:.2f}%). Saving model...")
        best_val_acc = epoch_val_acc
        torch.save(mlp.state_dict(), "checkpoint.pt")

end_train_time = time.time()
print(f"\nTraining finished in {end_train_time - start_train_time:.2f} seconds.")
print(f"Best validation accuracy: {best_val_acc:.2f}%" )

"""## 9. Plotting Training Results

"""

# Plot the validation loss and accuracy curves
plt.figure(figsize=(14, 6))

# Plot Validation Loss
plt.subplot(1, 2, 1)
plt.plot(range(1, num_epochs + 1), val_losses, marker='o', linestyle='-')
plt.xlabel("Epoch")
plt.ylabel("Validation Loss")
plt.title("Epoch vs. Validation Loss")
plt.grid(True)

# Plot Validation Accuracy
plt.subplot(1, 2, 2)
plt.plot(range(1, num_epochs + 1), val_accuracies, marker='o', linestyle='-', color='orange')
plt.xlabel("Epoch")
plt.ylabel("Validation Accuracy (%)")
plt.title("Epoch vs. Validation Accuracy")
plt.grid(True)

plt.tight_layout()
plt.show()

"""## 10. Helper Functions for Evaluation


"""

def evaluate_model(model, loader, device, use_half=False):
    """Evaluates accuracy over the dataset and measures inference time."""
    model.eval()  # Set model to evaluation mode
    correct = 0
    total = 0
    start_time = time.time()

    with torch.no_grad(): # Disable gradient calculation for evaluation
        for data, target in loader:
            data, target = data.to(device), target.to(device)
            # Convert input data to half precision if required
            if use_half:
                data = data.half()
            # Get model predictions
            outputs = model(data)
            # Get the index of the max log-probability (predicted class)
            _, predicted = torch.max(outputs.data, 1)
            total += target.size(0)
            correct += (predicted == target).sum().item()

    end_time = time.time()
    inference_time = (end_time - start_time) * 1000  # Convert to milliseconds
    accuracy = 100.0 * correct / total
    print(f"Evaluation completed in {inference_time:.2f} ms. Accuracy: {accuracy:.2f}%")
    return accuracy, inference_time

def get_model_file_size(model, filename="temp_model.pt"):
    """Saves the model state temporarily and returns file size in MB."""
    # Ensure model is on CPU before saving for consistent size measurement if needed,
    # but state_dict size is generally independent of device it was trained on.
    torch.save(model.state_dict(), filename)
    # Get file size in bytes and convert to Megabytes
    size_bytes = os.path.getsize(filename)
    size_mb = size_bytes / (1024 * 1024)
    # Remove the temporary file
    os.remove(filename)
    print(f"Calculated model size: {size_mb:.2f} MB")
    return size_mb

"""## 11. Evaluate Original Model (FP32)

"""

# Load the best performing checkpoint
print("Loading best model checkpoint...")
mlp.load_state_dict(torch.load("checkpoint.pt", map_location=device))
mlp.to(device) # Ensure model is on the correct device

# Evaluate the original model
print("\nEvaluating Original FP32 Model on Test Set:")
orig_acc, orig_infer_time = evaluate_model(mlp, test_loader, device)
orig_size = get_model_file_size(mlp, "orig_model.pt")

print("--- Original Model Summary ---")
print(f"Accuracy: {orig_acc:.2f}% | Inference Time: {orig_infer_time:.2f} ms | Storage: {orig_size:.2f} MB")

"""## 12. Apply and Evaluate Dynamic Quantization (INT8)

"""

# Apply Dynamic Quantization
print("\nApplying Dynamic Quantization...")
# Ensure the original model (best checkpoint) is loaded and on the CPU for quantization
# Note: Dynamic Quantization typically targets CPU execution
mlp_cpu = MLP()
mlp_cpu.load_state_dict(torch.load("checkpoint.pt", map_location="cpu"))
mlp_cpu.eval() # Set to evaluation mode before quantization

dynamic_model = quant.quantize_dynamic(
    mlp_cpu, {nn.Linear}, dtype=torch.qint8
)

# Dynamic quantization primarily benefits CPU, so evaluate on CPU
quant_device = torch.device("cpu")
dynamic_model.to(quant_device)
print(f"Quantized model placed on: {quant_device}")

# Evaluate the dynamic quantized model
print("\nEvaluating Dynamic Quantization (INT8) Model on Test Set:")
dyn_acc, dyn_infer_time = evaluate_model(dynamic_model, test_loader, quant_device)
dyn_size = get_model_file_size(dynamic_model, "dynamic_model.pt")

print("--- Dynamic Quantization Model Summary ---")
print(f"Accuracy: {dyn_acc:.2f}% | Inference Time: {dyn_infer_time:.2f} ms | Storage: {dyn_size:.2f} MB")

"""## 13. Apply and Evaluate Half Precision (FP16)


"""

# Reload the original model weights before converting to half precision
print("\nReloading best model checkpoint for FP16 conversion...")
mlp.load_state_dict(torch.load("checkpoint.pt", map_location=device))
mlp.to(device) # Ensure model is on the correct device
mlp.eval() # Set to eval mode

# Convert model to half precision
print("Converting model to Half Precision (FP16)...")
half_model = mlp.half()
# Ensure the half model is on the GPU if available, as FP16 benefits are mainly on GPU
half_model.to(device)
print(f"Half precision model placed on: {device}")

# Evaluate the half precision model
# Note: Requires input data to be converted to half() as well.
print("\nEvaluating Half Precision (FP16) Model on Test Set:")
half_acc, half_infer_time = evaluate_model(half_model, test_loader, device, use_half=True)
half_size = get_model_file_size(half_model, "half_model.pt")

print("--- Half Precision Model Summary ---")
print(f"Accuracy: {half_acc:.2f}% | Inference Time: {half_infer_time:.2f} ms | Storage: {half_size:.2f} MB")

"""## 14. Comparison Summary

"""

# Create a PrettyTable instance
table = PrettyTable()
table.field_names = ["S.No.", "Model Type", "Accuracy (%)", "Storage (MB)", "Inference Time (ms)"]
table.align = "l"
table.align["Accuracy (%)"] = "r"
table.align["Storage (MB)"] = "r"
table.align["Inference Time (ms)"] = "r"

# Add rows for each model
table.add_row([1, "Original (FP32)", f"{orig_acc:.2f}", f"{orig_size:.2f}", f"{orig_infer_time:.2f}"])
table.add_row([2, "Dynamic Quantized (INT8)", f"{dyn_acc:.2f}", f"{dyn_size:.2f}", f"{dyn_infer_time:.2f}"])
table.add_row([3, "Half Precision (FP16)", f"{half_acc:.2f}", f"{half_size:.2f}", f"{half_infer_time:.2f}"])

# Print the comparison table
print("\n===== Model Optimization Techniques Comparison =====")
print(table)
